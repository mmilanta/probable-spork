\documentclass{article}
\usepackage{amsmath, amssymb, amsthm}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}

% ---------- Reusable commands ----------
\newcommand{\Bp}{B^{(p)}}
\newcommand{\Xp}{X^{(p)}}
\newcommand{\bp}{b^{(p)}}
\newcommand{\var}{\mathbb{V}}
\newcommand{\cov}{\text{Cov}}
\newcommand{\taup}{\tau^{(p)}}
\newcommand{\Pp}{\mathbb{P}_p}
\newcommand{\Ep}{\mathbb{E}_p}
\newcommand{\hh}{h}
\newcommand{\Dlt}{\Delta}
\newcommand{\win}{W}
\newcommand{\lose}{L}
\newcommand{\start}{s}
\newcommand{\x}{\mathbf{X}}
\newcommand{\xgp}{\x^{\left(G, s, p\right)}}
\newcommand{\xge}{\x^{\left(G, s, 1/2 + \varepsilon\right)}}
\newcommand{\xghalf}{\x^{\left(G, s, 1/2\right)}}
\newcommand{\taugp}{{\tau^{\left(G, s, p\right)}}}
\newcommand{\taughalf}{{\tau^{\left(G, s, 1/2\right)}}}
\newcommand{\tauge}{{\tau^{\left(G, s, 1/2 + \varepsilon\right)}}}
\newcommand{\mge}{\m^{\left(G, s, 1/2 + \varepsilon\right)}}
\newcommand{\mgp}{\m^{\left(G, s, p\right)}}
\newcommand{\mghalf}{\m^{\left(G, s, 1/2\right)}}
\newcommand{\m}{M}
\newcommand{\out}{O}
\newcommand{\outgp}{{O^{\left(G, s, p\right)}}}
\newcommand{\ex}{\mathbb{E}}
\newcommand{\pr}{\mathbb{P}}
\newcommand{\fair}{\mathcal{F}}
\newcommand{\h}{h}
% ---------------------------------------

\begin{document}
\title{Optimal Game Structure Inequality}
\author{Marco Milanta}
\date{February 15, 2026}
\maketitle

\begin{abstract}
We prove the fairness--length inequality for general game graphs.
\end{abstract}

\section*{Probelm Formalization}
To state the result rigoursly, we need to formally define all the objects. We begin by the game graph.

\begin{definition}[Game graph]
Let $G = (V, E)$ be a directed graph with two absorbing vertices \(\win\) and \(\lose\). Every other vertex \(v\) has two outgoing edges $v\to v_+$ and $v\to v_-$.

Furthermore, we denote a single vertex $\start\in V\setminus \{\win,\lose\}$ as starting node.
\end{definition}

The game graph is the matemathical structure we will use to describe a tennis match. The vertexes are all the possible states of the match: each will correspond to a specific (punteggio in inglese). From a state $v$, if the first player wins, the game will transition to $v_+$, else to $v_-$. The game being won by the first player corresponds to ending in $\win$, lost in $\lose$.

Now we define the match itself as a random walk on the graph.

\begin{definition}[Graph walk]
Given a game graph $G = (V, E)$, $\start \in V$ and $p \in [0,1]$. We define $\xgp$
to be a stocastic process on $G$ starting from the starting the node $\xgp_0 = \start$, and with
$$
\xgp_{i+1}= \begin{cases}
\left(\xgp_i\right)_+ & \text{with prob. } p, \\
\left(\xgp_i\right)_- & \text{with prob } 1 - p,
\end{cases}
$$
while $\xgp_i\notin \{\win, \lose\}$, after that the random process ends. We call $\taugp \in \mathbb N \cup\{\infty\}$ the number of steps needed to reach $\{\win, \lose\}$. Finally, if $\taugp<\infty$ we call the final state $\outgp = \xgp_\taugp \in \{\win, \lose\}$.
\end{definition}


The graph walk is the stocastic process corresponding to playing a match in the structure defined by $G$, and starting from punteggio 0 a 0, which corresponds to the node $s$. To continue with the paralles, $\taugp$ is the number of points played during the match, and $\xgp_\taugp$ is the outcome of the match.

Of course, in our analysis we are interested in those games which are balanced, meaning that assumping the first player is just as strong as the second one $\left(p=1/2\right)$, then the probability of the first player to win the match is also $1/2$, formally this means that:
$$
\pr \left( \out_{(G, s, 1/2)} = \win\right)= \frac12.
$$
The last thing remained to defined is the fairness of the match. This is a quantity that indicates how much the stronger player actually benefits from the game structure. 

\begin{definition}[Game Fairness]
Given a game graph $G = (V, E)$, and a starting point $s$, we call the fairness of the match
$$
\fair(G, s) := \frac{d}{dp}\pr \left( \outgp = \win\right)\Big\vert_{p=\frac12}.
$$
\end{definition}
While this definition could look esoteric there is a nice way to think about it. Assume the first player has an edge of $\varepsilon$, meaning that $p = 1/2 + \varepsilon$, then we will have that
$$
\pr\left(\out_{(G, s, 1/2 + \varepsilon)} = \win\right) = \frac12 + \varepsilon\fair(G, s) + o(\varepsilon).
$$
Thus, $\fair$ can be seen as the advantage moltiplicator factor for small $\varepsilon$.

\section*{Main Result}
\begin{theorem}
Given a game graph $G$ and a starting position $s$, such that the game is balanced
$$
\pr \left( \out^{(G, s, 1/2)} = \win\right)= \frac12, 
$$
and the match has no hidden status
$$
\xgp_i \vert \xgp_{0}, \dots, \xgp_{i-1} = \xgp_i \vert \xgp_{i-1},
$$
then
$$
\fair(G, s)\leq \left(\ex[\tau_{(G, s, 1/2)}]\right)^2.
$$
\end{theorem}
This is result is tight, as we can see by the optimal game structure defined in the blog post.
The two assumptions we do are also quite natural. The first one is that we are talking about a balanced match structure, where the first player has no inherit advantage to the second one. The second one is more subdle, and likely it does not hold in practice, basically we are assuming that the players will play each point indipendently of how the previous points in the match went. This assumption is however necessary, without it the result does not hold.

\section*{Proof}
The proof is devided in three parts. First we do a perturbation argument to derive a powerful formula to express the fairness $\fair(G, s)$, then we do an energy bound. Finally, we use the Cauchy--Schwarz inequality to derive the final bound. We first start by defining the key quantities we will use.
\subsection*{Definitions}
\begin{definition}[Value function]
    $$
    \h_{(G)}: V \to [0,1], \quad\quad \h_{(G)}(v) = \pr\left( \out^{(G, v, 1/2)} = \win\right).
    $$
\end{definition}
Thus, $\h_{(G)}(v)$ is the probability for the first player to win, given that the first player is just as strong as the second one $(p= 1/2)$, and given that the current punteggio situation is $v$.
Note that $\h_{(G)}(v)$ is not a random variable, and it always assumes that $p = 1/2$.

This quantity is a good proxy for the state of the match, instead of a messy punteggio, which could be missleading, this indicates well how far (probabilistically) is a player from winning the match.

We now show that $\h_{(G)}(v)$ has a key harmoinc property, that later on will be crucial.
\begin{lemma}[$\h_{(G)}(v)$ is harmonic] Given and edge $v\in G\setminus\{\win, \lose\}$, let $v_+$ and $v_-$ be the vertexes reached by the outward edges from $v$, then  
$$
\h_{(G)}(v) = \frac12\left(\h_{(G)}(v_+) + \h_{(G)}(v_-) \right).
$$

\end{lemma}
\begin{proof}
The proof comes from rolling out one step of the random walk.
\begin{align*}
    \h_{(G)}(v) &= \pr\left( \out^{(G, v, 1/2)} = \win\right) \\
    &\overset{(1)}{=} \pr\left( \out^{(G, v, 1/2)} = \win\vert \x^{(G, v, 1/2)}_1 = v_+\right)\pr\left(  \x^{(G, v, 1/2)}_1 = v_+\right) + \\ &\quad\quad\pr\left( \out^{(G, v, 1/2)} = \win\vert \x^{(G, v, 1/2)}_1 = v_-\right)\pr\left(  \x^{(G, v, 1/2)}_1 = v_-\right) \\
    &\overset{(2)}{=}\h_{(G)}(v_+)\pr\left(  \x^{(G, v, 1/2)}_1 = v_+\right) +  \h_{(G)}(v_-)\pr\left(\x^{(G, v, 1/2)}_1 = v_-\right) \\
    & \overset{(3)}{=} \frac12 \h_{(G)}(v_+) + \frac12\h_{(G)}(v_-),
\end{align*}
where $(1)$ is due to the law of total probability, dividing the probability space between the two possible outcomes of the first step. $(2)$ follows from the definition of $\h_{(G)}(v)$. $(3)$ follows from the fact that we are looking at $\x^{(G, v, 1/2)}$, thus there is a $1/2$ probability of winning the first step.
\end{proof}

Now that we defined the value function $\h_{(G)}(v)$, we introduce one more quantity
\begin{definition}[Importance function]
$$
\Delta_G(v) := \h_{(G)}(v_+) - \h_{(G)}(v_-).
$$
\end{definition}
This function indicates how much probability is at stake in a given situation $v$. If the game is balanced, if the first player wins the next point, then his probability of winning will go up by $\Delta_G(v)/2$. This quantity is a good proxy to indentify pressure points as matchpoints in a game.
look at the stocastic value of $\h_{(G)}(v)$ over the course of the match.

Now that we defined those non-aleatoric quantities, we can conver the problem with a probability distribution. Thus we define the following random process.
\begin{definition}[Stochastic Value Process]
We define $\mgp$ as follows:
$$
\mgp := \left(\h\left(\xgp_0\right), \h\left(\xgp_1\right), \dots, \h\left(\xgp_\taugp\right)\right).
$$
\end{definition}
The name $\mgp$ is motivated by the fact that, in the specific case of $p=1/2$, $\m^{(G, s, 1/2)}$ is a martingale.

To motivate these constructions, we notice that
$$
\pr\left( \out^{(G, s, p)} = \win\right) = \ex\left[\mgp_\taugp\right].
$$
The reason is that $\xgp_\taugp$ is either $\win$ or $\lose$, thus $\mgp_\taugp$ is the either $1$ or $0$, thus $ \ex\left[\mgp_\taugp\right]$ is the probability that $\mgp_\taugp$ is $1$.

Furthermore, because the match is balanced (one of the conditions we assumed), $\mgp_{0} = \h\left(\xgp_0\right) = 1/2$. Thus, $\mgp$ is a stocastic process which starts at $1/2$ and ends at $1$ or $0$, but even more interestingly, the expected value of $\mgp$ starts from $1/2$ and ends at the probability of winning the match.

\subsection*{Perturbation argument}

As we discussed before, $\m^{(G, s, 1/2)}$ is a martingale, thus 
$$
\ex\left[\mgp_i\right] = 1/2 \quad \forall i.
$$
We now examin what happens if we perturb the match structure slightly from $1/2$. So we compute the probability of winning with $p = 1/2 + \varepsilon$.
\begin{align*}
    \pr&\left(\out^{(G, s, 1/2 + \varepsilon)} = \win\right) = \ex\left[\mge_\tauge\right]\\
    &= \ex\left[\underbrace{\mge_0}_{=1/2} + \sum_{i=0}^{\tauge} \left(\mge_i - \mge_{i-1}\right)\right] \\
    &= \frac12 + \ex\left[\sum_{i=0}^{\infty} 1_{i \leq \tauge}\left(\mge_i - \mge_{i-1}\right)\right]\\
    &\overset{(1)}{=} \frac12 +\sum_{i=0}^{\infty} \ex\left[1_{i \leq \tauge}\left(\mge_i - \mge_{i-1}\right)\right]\\
    &\overset{(2)}{=} \frac12 +\sum_{i=0}^{\infty} \ex\left[\mge_i - \mge_{i-1}\right]\\
    &\overset{(3)}{=} \frac12 +\sum_{i=0}^{\infty} \ex\left[\ex\left[\mge_i - \mge_{i-1}\vert \xge_{i-1}\right]\right]\\
    &\overset{(4)}{=} \frac12 +\varepsilon \sum_{i=0}^{\infty} \ex\left[\Delta_G\left(\xge_{i-1}\right)\right].\\
    &\overset{(5)}{=} \frac12 +\varepsilon \; \ex\left[\sum_{i=0}^{\tauge} \Delta_G\left(\xge_{i-1}\right)\right].\\
\end{align*}
In $(1)$ we use the fact that the quantity we are trying to bound is a probability, thus is between $0$ and $1$, and thus we can swap the sum and the expectation.
In $(2)$ we use a trick, we momentanly define $\mge_i = \mge_{\tauge}$ for $i > \tauge$. In $(3)$ we use the law of total expectation. Finally, $(4)$ is justified right after.
\begin{align*}
& \ex\left[\left(\h\left(\xge_i\right) - \h\left(\xge_{i-1}\right)\right)\vert \xge_{i-1}\right] = \\
&= \underbrace{\frac12\left(\h\left(\left(\xge_{i-1}\right)_+\right) + \h\left(\left(\xge_{i-1}\right)_-\right)\right) - \h\left(\xge_{i-1}\right)}_{= 0 \text{ because } \h \text{ is harmonic}} + \\
& \quad\quad + \varepsilon \underbrace{\left(\h\left(\left(\xge_{i-1}\right)_+\right) - \h\left(\left(\xge_{i-1}\right)_-\right)\right)}_{:= \Delta_G\left(\xge_{i-1}\right)} \\
&= \varepsilon \Delta_G\left(\xge_{i-1}\right).
\end{align*}

Finally we can compute the derivative of the probability of winning as the limit of the perturbation argument.
\begin{align*}
    \frac{d}{dp} \pr\left(\out^{(G, s, p)} = \win\right)&  \Big\vert_{p=1/2} = \lim_{\varepsilon \to 0} \frac{\pr\left(\out^{(G, s, 1/2 + \varepsilon)} = \win\right) - \pr\left(\out^{(G, s, 1/2)} = \win\right)}{\varepsilon} \\
    &= \lim_{\varepsilon \to 0} \frac{\frac12 + \varepsilon \ex\left[\sum_{i=0}^{\tauge} \Delta_G\left(\xge_{i-1}\right)\right] - \frac12}{\varepsilon} \\
    &= \lim_{\varepsilon \to 0} \ex\left[\sum_{i=0}^{\tauge} \Delta_G\left(\xge_{i-1}\right)\right] \\
    &= \ex\left[\sum_{i=0}^{\tau^{G, s, 1/2}} \Delta_G\left(\x^{G, s, 1/2}_{i-1}\right)\right]. \\
\end{align*}
Thus, finally we have
\begin{equation}
    \fair(G, s) = \ex\left[\sum_{i=0}^{\infty} \Delta_G\left(\x^{G, s, 1/2}_{i-1}\right)\right].
\end{equation}
This concludes the perturbation argument. 
\subsection*{Variance identity}

In the perturbation argument we have focused on the expected value of $\mgp$ over the course of the match. Now we focus on the variance instead. Similar to the perturbation argument, we will use a telescoping argument to express the variance of $\mghalf$ over the course of the match, toghether with a key insight on the variance of the $\mghalf_\taughalf$ function.

Because the match is balanced, we know that the probability of winning the match is $1/2$, thus $\mghalf_\taughalf \sim \text{Bernoulli}(1/2)$. Thus
\begin{equation}
    \var\left(\mghalf_\taughalf\right) = \var\left(\text{Bernoulli}(1/2)\right) =  \frac14.
\end{equation}
Now we can use the telescoping argument to express the variance of $\mghalf$ over the course of the match.
\begin{align*}
    \var & \left(\mghalf_\taughalf\right) = \var\left(\mghalf_0 + \sum_{i=1}^{\taughalf} \left(\mghalf_i - \mghalf_{i-1}\right)\right) \\
    &\overset{(1)}{=}\var\left(\sum_{i=1}^{\taughalf} \left(\mghalf_i - \mghalf_{i-1}\right)\right) \\
    &\overset{(2)}{=}\var\left(\sum_{i=1}^{\taughalf}\frac12 \Delta_G\left(\xghalf_{i-1}\right)  b_{i-1} \right)\\
    &=\frac14 \sum_{i=1}^{\taughalf} \sum_{j=1}^{\taughalf}\cov\left(\Delta_G\left(\xghalf_{i-1}\right)  b_{i-1}, \Delta_G\left(\xghalf_{j-1}\right)  b_{j-1} \right)\\
    &\overset{(3)}{=}\frac14 \sum_{i=1}^{\taughalf} \var\left(\Delta_G\left(\xghalf_{i-1}\right) b_{i-1}\right)\\
    &\overset{(4)}{=}\frac14 \sum_{i=1}^{\taughalf} \ex\left[\Delta_G\left(\xghalf_{i-1}\right)^2\right]\\
\end{align*}

Where $(1)$ is due to the fact that $\mghalf_0 = 1/2$, and translations do not contribute to the variance. In $(2)$ we introduce a random variable that is $1$ if the process goes on the $+$ edge, and $-1$ if it goes on the $-$ edge. Notice that $b_i\overset{\text{i.i.d.}}{\sim} \text{Rademacher}(1/2)$; indipendence follows from the second assumption we made. In $(3)$ we use the aformentioned indipendence to cancel out all the cross-terms. In $(4)$ we use the fact $\ex[b_i] = 0$, thus the variance is the expected value of the square.

Combining this with equation $(2)$ we get
\begin{equation}
    \sum_{i=1}^{\taughalf} \ex\left[\Delta_G\left(\xghalf_{i-1}\right)^2\right] = 1
\end{equation}
This concludes the variance identity. 

\subsection*{Cauchy--Schwarz inequality}
The last step to complete the proof, is to use the Cauchy--Schwarz
\begin{align*}
    \fair(G, s)^2 &\overset{(1)}{=} \ex\left[\sum_{i=0}^{\taughalf} \Delta_G\left(\xghalf_{i-1}\right)\right]^2 \\
    &= \ex\left[\sum_{i=0}^{\taughalf} 1 \;\Delta_G\left(\xghalf_{i-1}\right)\right]^2 \\
    &\leq \underbrace{\ex\left[\sum_{i=0}^{\taughalf} \Delta_G\left(\xghalf_{i-1}\right)^2\right]}_{= 1 \text{ due to variance identity}} \ex\left[\sum_{i=0}^{\taughalf} 1\right]\\
    &= \ex\left[\sum_{i=0}^{\taughalf} 1\right] = \ex\left[\taughalf\right].
\end{align*}
Where $(1)$ is due to equation $(1)$ in the perturbation argument. This concludes the proof.
\end{document}
